RewardPredictor(
  (image_encoder): ImageEncoder(
    (conv_layers): Sequential(
      (0): Conv2d(3, 4, kernel_size=(3, 3), stride=(2, 2))
      (1): ReLU()
      (2): Conv2d(4, 8, kernel_size=(3, 3), stride=(2, 2))
      (3): ReLU()
      (4): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2))
      (5): ReLU()
      (6): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2))
      (7): ReLU()
      (8): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2))
      (9): ReLU()
    )
    (projection): Linear(in_features=64, out_features=64, bias=True)
  )
  (lstm_predictor): LSTMPredictor(
    (lstm): LSTM(64, 64, batch_first=True)
    (mlpk): ModuleDict(
      (agent_x): MLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
          (3): ReLU()
          (4): Linear(in_features=32, out_features=1, bias=True)
        )
      )
      (agent_y): MLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
          (3): ReLU()
          (4): Linear(in_features=32, out_features=1, bias=True)
        )
      )
      (target_x): MLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
          (3): ReLU()
          (4): Linear(in_features=32, out_features=1, bias=True)
        )
      )
      (target_y): MLP(
        (mlp): Sequential(
          (0): Linear(in_features=64, out_features=32, bias=True)
          (1): ReLU()
          (2): Linear(in_features=32, out_features=32, bias=True)
          (3): ReLU()
          (4): Linear(in_features=32, out_features=1, bias=True)
        )
      )
    )
  )
)
[0.868s] step=0 loss=0.21477
[0.760s] step=1 loss=0.22636
[0.686s] step=2 loss=0.22572
[0.671s] step=3 loss=0.21851
[0.666s] step=4 loss=0.21521
[0.673s] step=5 loss=0.17029
[0.676s] step=6 loss=0.17320
[0.670s] step=7 loss=0.18673
[0.685s] step=8 loss=0.15861
[0.682s] step=9 loss=0.15291
[0.667s] step=10 loss=0.16244
[0.667s] step=11 loss=0.13750
[0.673s] step=12 loss=0.11617
[0.671s] step=13 loss=0.11265
[0.682s] step=14 loss=0.11789
[0.664s] step=15 loss=0.08740
[0.671s] step=16 loss=0.09880
[0.677s] step=17 loss=0.08806
[0.674s] step=18 loss=0.08119
[0.670s] step=19 loss=0.08157
[0.680s] step=20 loss=0.06978
[0.686s] step=21 loss=0.05778
[0.678s] step=22 loss=0.06087
[0.661s] step=23 loss=0.05508
[0.669s] step=24 loss=0.05768
[0.676s] step=25 loss=0.05406
[0.664s] step=26 loss=0.05932
[0.662s] step=27 loss=0.05642
[0.674s] step=28 loss=0.05890
[0.677s] step=29 loss=0.05730
[0.669s] step=30 loss=0.05654
[0.696s] step=31 loss=0.05868
[0.669s] step=32 loss=0.05758
[0.665s] step=33 loss=0.05498
[0.660s] step=34 loss=0.05654
[0.692s] step=35 loss=0.05802
[0.683s] step=36 loss=0.05361
[0.666s] step=37 loss=0.05694
[0.681s] step=38 loss=0.05744
[0.689s] step=39 loss=0.05389
[0.694s] step=40 loss=0.05571
[0.675s] step=41 loss=0.05356
[0.674s] step=42 loss=0.05428
[0.681s] step=43 loss=0.05714
[0.685s] step=44 loss=0.05614
[0.689s] step=45 loss=0.05063
[0.678s] step=46 loss=0.05661
[0.669s] step=47 loss=0.05656
[0.652s] step=48 loss=0.05386
[0.661s] step=49 loss=0.05252
[0.671s] step=50 loss=0.04802
[0.680s] step=51 loss=0.05170
[0.666s] step=52 loss=0.05371
[0.668s] step=53 loss=0.05573
[0.695s] step=54 loss=0.05346
[0.670s] step=55 loss=0.05326
[0.672s] step=56 loss=0.05433
[0.670s] step=57 loss=0.05208
[0.685s] step=58 loss=0.05168
[0.673s] step=59 loss=0.04718
[0.672s] step=60 loss=0.05220
[0.667s] step=61 loss=0.04990
[0.686s] step=62 loss=0.05332
[0.668s] step=63 loss=0.05619
[0.664s] step=64 loss=0.05073
[0.671s] step=65 loss=0.05186
[0.675s] step=66 loss=0.04956
[0.667s] step=67 loss=0.04930
[0.664s] step=68 loss=0.04950
[0.663s] step=69 loss=0.05619
[0.670s] step=70 loss=0.05109
[0.684s] step=71 loss=0.05075
[0.668s] step=72 loss=0.04623
[0.669s] step=73 loss=0.04832
[0.676s] step=74 loss=0.04204
[0.668s] step=75 loss=0.04334
[0.659s] step=76 loss=0.04378
[0.657s] step=77 loss=0.04239
[0.656s] step=78 loss=0.04244
[0.690s] step=79 loss=0.04134
[0.679s] step=80 loss=0.04514
[0.691s] step=81 loss=0.04169
[0.673s] step=82 loss=0.04066
[0.672s] step=83 loss=0.04101
[0.691s] step=84 loss=0.04046
[0.661s] step=85 loss=0.04233
[0.674s] step=86 loss=0.03786
[0.669s] step=87 loss=0.03956
[0.668s] step=88 loss=0.03419
[0.669s] step=89 loss=0.03701
[0.672s] step=90 loss=0.03797
[0.672s] step=91 loss=0.03537
[0.661s] step=92 loss=0.03267
[0.661s] step=93 loss=0.03220
[0.670s] step=94 loss=0.03691
[0.670s] step=95 loss=0.02981
[0.661s] step=96 loss=0.02938
[0.663s] step=97 loss=0.02760
[0.683s] step=98 loss=0.03252
[0.666s] step=99 loss=0.02784
saved model to ./logs/reward_model_2/step-99.pth
[0.691s] step=100 loss=0.02562
[0.699s] step=101 loss=0.02843
[0.717s] step=102 loss=0.03214
[0.684s] step=103 loss=0.02997
[0.679s] step=104 loss=0.03283
[0.676s] step=105 loss=0.02904
[0.666s] step=106 loss=0.02954
[0.676s] step=107 loss=0.03328
[0.685s] step=108 loss=0.02868
[0.657s] step=109 loss=0.02940
[0.666s] step=110 loss=0.03104
[0.668s] step=111 loss=0.02793
[0.660s] step=112 loss=0.02686
[0.662s] step=113 loss=0.03049
[0.664s] step=114 loss=0.02820
[0.672s] step=115 loss=0.03011
[0.680s] step=116 loss=0.02973
[0.655s] step=117 loss=0.02619
[0.671s] step=118 loss=0.02728
[0.674s] step=119 loss=0.02629
[0.672s] step=120 loss=0.02807
[0.669s] step=121 loss=0.02481
[0.678s] step=122 loss=0.02862
[0.664s] step=123 loss=0.02374
[0.675s] step=124 loss=0.02759
[0.675s] step=125 loss=0.02638
[0.676s] step=126 loss=0.02405
[0.677s] step=127 loss=0.02385
[0.671s] step=128 loss=0.02367
[0.679s] step=129 loss=0.02519
[0.687s] step=130 loss=0.02354
[0.666s] step=131 loss=0.02347
[0.687s] step=132 loss=0.02568
[0.677s] step=133 loss=0.02602
[0.684s] step=134 loss=0.02280
[0.664s] step=135 loss=0.02297
[0.678s] step=136 loss=0.02124
[0.670s] step=137 loss=0.02424
[0.672s] step=138 loss=0.02025
[0.673s] step=139 loss=0.02278
[0.662s] step=140 loss=0.02047
[0.674s] step=141 loss=0.02037
[0.670s] step=142 loss=0.02053
[0.695s] step=143 loss=0.02067
[0.704s] step=144 loss=0.01955
[0.710s] step=145 loss=0.01921
[0.707s] step=146 loss=0.01717
[0.683s] step=147 loss=0.01738
[0.687s] step=148 loss=0.01740
[0.671s] step=149 loss=0.01904
[0.671s] step=150 loss=0.01541
[0.675s] step=151 loss=0.01646
[0.674s] step=152 loss=0.01593
[0.666s] step=153 loss=0.01574
[0.669s] step=154 loss=0.01764
[0.665s] step=155 loss=0.01557
[0.669s] step=156 loss=0.01369
[0.660s] step=157 loss=0.01420
[0.664s] step=158 loss=0.01300
[0.676s] step=159 loss=0.01390
[0.671s] step=160 loss=0.01159
[0.666s] step=161 loss=0.01222
[0.702s] step=162 loss=0.01183
[0.678s] step=163 loss=0.01376
[0.654s] step=164 loss=0.01011
[0.670s] step=165 loss=0.01032
[0.682s] step=166 loss=0.01272
[0.668s] step=167 loss=0.01121
[0.663s] step=168 loss=0.00983
[0.674s] step=169 loss=0.01051
[0.687s] step=170 loss=0.01011
[0.679s] step=171 loss=0.01007
[0.669s] step=172 loss=0.01032
[0.674s] step=173 loss=0.00903
[0.661s] step=174 loss=0.00871
[0.696s] step=175 loss=0.00929
[0.670s] step=176 loss=0.01053
[0.660s] step=177 loss=0.00841
[0.676s] step=178 loss=0.00871
[0.668s] step=179 loss=0.00884
[0.659s] step=180 loss=0.00769
[0.665s] step=181 loss=0.00757
[0.673s] step=182 loss=0.00771
[0.674s] step=183 loss=0.00825
[0.678s] step=184 loss=0.00833
[0.671s] step=185 loss=0.00909
[0.668s] step=186 loss=0.00756
[0.669s] step=187 loss=0.00676
[0.661s] step=188 loss=0.00764
[0.673s] step=189 loss=0.00716
[0.679s] step=190 loss=0.00772
[0.678s] step=191 loss=0.00711
[0.673s] step=192 loss=0.00660
[0.659s] step=193 loss=0.00720
[0.667s] step=194 loss=0.00655
[0.669s] step=195 loss=0.00806
[0.660s] step=196 loss=0.00696
[0.681s] step=197 loss=0.00651
[0.661s] step=198 loss=0.00651
[0.680s] step=199 loss=0.00687
saved model to ./logs/reward_model_2/step-199.pth
[0.675s] step=200 loss=0.00684
[0.700s] step=201 loss=0.00618
[0.755s] step=202 loss=0.00677
[0.668s] step=203 loss=0.00623
[0.674s] step=204 loss=0.00670
[0.672s] step=205 loss=0.00619
[0.671s] step=206 loss=0.00655
[0.680s] step=207 loss=0.00541
[0.657s] step=208 loss=0.00584
[0.691s] step=209 loss=0.00566
[0.690s] step=210 loss=0.00526
[0.710s] step=211 loss=0.00522
[0.754s] step=212 loss=0.00593
[0.684s] step=213 loss=0.00555
[0.690s] step=214 loss=0.00532
[0.674s] step=215 loss=0.00587
[0.672s] step=216 loss=0.00561
[0.690s] step=217 loss=0.00486
[0.708s] step=218 loss=0.00529
[0.682s] step=219 loss=0.00444
[0.688s] step=220 loss=0.00508
[0.694s] step=221 loss=0.00462
[0.674s] step=222 loss=0.00460
[0.689s] step=223 loss=0.00475
[0.670s] step=224 loss=0.00473
[0.668s] step=225 loss=0.00458
[0.665s] step=226 loss=0.00490
[0.666s] step=227 loss=0.00434
[0.653s] step=228 loss=0.00400
[0.698s] step=229 loss=0.00477
[0.678s] step=230 loss=0.00434
[0.688s] step=231 loss=0.00491
[0.674s] step=232 loss=0.00447
[0.663s] step=233 loss=0.00446
[0.657s] step=234 loss=0.00478
[0.658s] step=235 loss=0.00423
[0.664s] step=236 loss=0.00390
[0.678s] step=237 loss=0.00389
[0.664s] step=238 loss=0.00443
[0.669s] step=239 loss=0.00449
[0.675s] step=240 loss=0.00402
[0.671s] step=241 loss=0.00451
[0.673s] step=242 loss=0.00352
[0.704s] step=243 loss=0.00357
[0.709s] step=244 loss=0.00440
[0.702s] step=245 loss=0.00400
[0.668s] step=246 loss=0.00363
[0.707s] step=247 loss=0.00332
[0.775s] step=248 loss=0.00438
[0.727s] step=249 loss=0.00363
[1.073s] step=250 loss=0.00337
[0.718s] step=251 loss=0.00366
[0.729s] step=252 loss=0.00356
[0.721s] step=253 loss=0.00354
[0.793s] step=254 loss=0.00346
[0.834s] step=255 loss=0.00326
[0.769s] step=256 loss=0.00389
[0.764s] step=257 loss=0.00360
[0.878s] step=258 loss=0.00380
[0.879s] step=259 loss=0.00405
[0.715s] step=260 loss=0.00372
[0.707s] step=261 loss=0.00356
[0.696s] step=262 loss=0.00367
[0.669s] step=263 loss=0.00359
[0.681s] step=264 loss=0.00292
[0.696s] step=265 loss=0.00306
[0.663s] step=266 loss=0.00347
[0.674s] step=267 loss=0.00381
[0.726s] step=268 loss=0.00365
[0.725s] step=269 loss=0.00329
[0.725s] step=270 loss=0.00365
[0.713s] step=271 loss=0.00324
[0.731s] step=272 loss=0.00346
[0.738s] step=273 loss=0.00314
[0.698s] step=274 loss=0.00313
[0.693s] step=275 loss=0.00310
[0.719s] step=276 loss=0.00306
[0.741s] step=277 loss=0.00336
[0.768s] step=278 loss=0.00320
[0.735s] step=279 loss=0.00291
[0.702s] step=280 loss=0.00280
[0.687s] step=281 loss=0.00310
[0.706s] step=282 loss=0.00297
[0.757s] step=283 loss=0.00271
[0.829s] step=284 loss=0.00285
[0.974s] step=285 loss=0.00285
[0.842s] step=286 loss=0.00271
[0.894s] step=287 loss=0.00312
[0.753s] step=288 loss=0.00321
[0.738s] step=289 loss=0.00326
[0.723s] step=290 loss=0.00278
[0.724s] step=291 loss=0.00308
[0.733s] step=292 loss=0.00326
[0.715s] step=293 loss=0.00271
[0.746s] step=294 loss=0.00295
[0.729s] step=295 loss=0.00274
[0.741s] step=296 loss=0.00341
[0.685s] step=297 loss=0.00304
[0.680s] step=298 loss=0.00315
[0.692s] step=299 loss=0.00258
saved model to ./logs/reward_model_2/step-299.pth
[0.728s] step=300 loss=0.00303
[0.724s] step=301 loss=0.00299
[0.715s] step=302 loss=0.00294
[0.715s] step=303 loss=0.00309
[0.725s] step=304 loss=0.00306
[0.718s] step=305 loss=0.00318
[0.713s] step=306 loss=0.00322
[0.696s] step=307 loss=0.00278
[0.674s] step=308 loss=0.00254
[0.656s] step=309 loss=0.00311
[0.689s] step=310 loss=0.00270
[0.674s] step=311 loss=0.00260
[0.666s] step=312 loss=0.00269
[0.669s] step=313 loss=0.00305
[0.667s] step=314 loss=0.00279
[0.662s] step=315 loss=0.00320
[0.677s] step=316 loss=0.00278
[0.670s] step=317 loss=0.00239
[0.662s] step=318 loss=0.00253
[0.663s] step=319 loss=0.00232
[0.673s] step=320 loss=0.00251
[0.668s] step=321 loss=0.00216
[0.665s] step=322 loss=0.00229
[0.723s] step=323 loss=0.00272
[0.717s] step=324 loss=0.00245
[0.738s] step=325 loss=0.00232
[0.739s] step=326 loss=0.00210
[0.720s] step=327 loss=0.00229
[0.693s] step=328 loss=0.00227
[0.676s] step=329 loss=0.00254
[0.667s] step=330 loss=0.00223
[0.667s] step=331 loss=0.00262
[0.673s] step=332 loss=0.00226
[0.699s] step=333 loss=0.00288
[0.735s] step=334 loss=0.00209
[0.712s] step=335 loss=0.00229
[0.723s] step=336 loss=0.00224
[0.706s] step=337 loss=0.00289
[0.721s] step=338 loss=0.00256
[0.764s] step=339 loss=0.00243
[0.725s] step=340 loss=0.00230
[0.708s] step=341 loss=0.00235
[0.791s] step=342 loss=0.00273
[0.758s] step=343 loss=0.00250
[0.719s] step=344 loss=0.00238
[0.676s] step=345 loss=0.00250
[0.687s] step=346 loss=0.00211
[0.692s] step=347 loss=0.00230
[0.699s] step=348 loss=0.00252
[0.670s] step=349 loss=0.00239
[0.671s] step=350 loss=0.00217
[0.667s] step=351 loss=0.00210
[0.669s] step=352 loss=0.00249
[0.676s] step=353 loss=0.00212
[0.682s] step=354 loss=0.00236
[0.668s] step=355 loss=0.00232
[0.665s] step=356 loss=0.00201
[0.671s] step=357 loss=0.00229
[0.675s] step=358 loss=0.00193
[0.674s] step=359 loss=0.00249
[0.673s] step=360 loss=0.00196
[0.670s] step=361 loss=0.00239
[0.666s] step=362 loss=0.00209
[0.706s] step=363 loss=0.00196
[0.663s] step=364 loss=0.00191
[0.671s] step=365 loss=0.00199
[0.675s] step=366 loss=0.00278
[0.670s] step=367 loss=0.00220
[0.674s] step=368 loss=0.00254
[0.679s] step=369 loss=0.00205
[0.674s] step=370 loss=0.00267
[0.668s] step=371 loss=0.00249
[0.676s] step=372 loss=0.00212
[0.679s] step=373 loss=0.00262
[0.675s] step=374 loss=0.00251
[0.665s] step=375 loss=0.00199
[0.669s] step=376 loss=0.00245
[0.679s] step=377 loss=0.00213
[0.689s] step=378 loss=0.00218
[0.671s] step=379 loss=0.00240
[0.681s] step=380 loss=0.00233
[0.688s] step=381 loss=0.00235
[0.687s] step=382 loss=0.00258
[0.676s] step=383 loss=0.00200
[0.672s] step=384 loss=0.00214
[0.681s] step=385 loss=0.00198
[0.669s] step=386 loss=0.00186
[0.681s] step=387 loss=0.00176
[0.681s] step=388 loss=0.00204
[0.675s] step=389 loss=0.00184
[0.685s] step=390 loss=0.00184
[0.674s] step=391 loss=0.00185
[0.678s] step=392 loss=0.00157
[0.682s] step=393 loss=0.00162
[0.671s] step=394 loss=0.00166
[0.682s] step=395 loss=0.00171
[0.665s] step=396 loss=0.00172
[0.665s] step=397 loss=0.00164
[0.692s] step=398 loss=0.00214
[0.689s] step=399 loss=0.00189
saved model to ./logs/reward_model_2/step-399.pth
[0.683s] step=400 loss=0.00177
[0.694s] step=401 loss=0.00193
[0.718s] step=402 loss=0.00183
[0.671s] step=403 loss=0.00191
[0.659s] step=404 loss=0.00183
[0.670s] step=405 loss=0.00192
[0.673s] step=406 loss=0.00179
[0.674s] step=407 loss=0.00189
[0.680s] step=408 loss=0.00151
[0.672s] step=409 loss=0.00193
[0.680s] step=410 loss=0.00136
[0.663s] step=411 loss=0.00151
[0.670s] step=412 loss=0.00155
[0.671s] step=413 loss=0.00174
[0.671s] step=414 loss=0.00152
[0.683s] step=415 loss=0.00193
[0.673s] step=416 loss=0.00154
[0.688s] step=417 loss=0.00166
[0.667s] step=418 loss=0.00195
[0.675s] step=419 loss=0.00176
[0.695s] step=420 loss=0.00159
[0.688s] step=421 loss=0.00177
[0.672s] step=422 loss=0.00173
[0.687s] step=423 loss=0.00169
[0.668s] step=424 loss=0.00155
[0.673s] step=425 loss=0.00172
[0.666s] step=426 loss=0.00165
[0.674s] step=427 loss=0.00156
[0.677s] step=428 loss=0.00174
[0.688s] step=429 loss=0.00162
[0.675s] step=430 loss=0.00173
[0.669s] step=431 loss=0.00166
[0.666s] step=432 loss=0.00177
[0.688s] step=433 loss=0.00165
[0.671s] step=434 loss=0.00137
[0.664s] step=435 loss=0.00142
[0.668s] step=436 loss=0.00156
[0.673s] step=437 loss=0.00176
[0.663s] step=438 loss=0.00170
[0.669s] step=439 loss=0.00169
[0.678s] step=440 loss=0.00171
[0.665s] step=441 loss=0.00146
[0.679s] step=442 loss=0.00168
[0.685s] step=443 loss=0.00155
[0.666s] step=444 loss=0.00164
[0.669s] step=445 loss=0.00165
[0.670s] step=446 loss=0.00149
[0.664s] step=447 loss=0.00159
[0.672s] step=448 loss=0.00146
[0.662s] step=449 loss=0.00152
[0.670s] step=450 loss=0.00152
[0.688s] step=451 loss=0.00145
[0.673s] step=452 loss=0.00150
[0.665s] step=453 loss=0.00153
[0.670s] step=454 loss=0.00131
[0.696s] step=455 loss=0.00126
[0.687s] step=456 loss=0.00175
[0.682s] step=457 loss=0.00157
[0.673s] step=458 loss=0.00161
[0.683s] step=459 loss=0.00145
[0.668s] step=460 loss=0.00118
[0.662s] step=461 loss=0.00148
[0.681s] step=462 loss=0.00142
[0.669s] step=463 loss=0.00167
[0.671s] step=464 loss=0.00150
[0.669s] step=465 loss=0.00156
[0.667s] step=466 loss=0.00157
[0.676s] step=467 loss=0.00154
[0.667s] step=468 loss=0.00139
[0.673s] step=469 loss=0.00137
[0.682s] step=470 loss=0.00135
[0.685s] step=471 loss=0.00148
[0.681s] step=472 loss=0.00139
[0.688s] step=473 loss=0.00133
[0.665s] step=474 loss=0.00143
[0.674s] step=475 loss=0.00141
[0.671s] step=476 loss=0.00132
[0.685s] step=477 loss=0.00116
[0.678s] step=478 loss=0.00147
[0.673s] step=479 loss=0.00124
[0.675s] step=480 loss=0.00127
[0.675s] step=481 loss=0.00123
[0.699s] step=482 loss=0.00134
[0.683s] step=483 loss=0.00136
[0.680s] step=484 loss=0.00125
[0.671s] step=485 loss=0.00114
[0.679s] step=486 loss=0.00105
[0.689s] step=487 loss=0.00137
[0.676s] step=488 loss=0.00142
[0.673s] step=489 loss=0.00132
[0.669s] step=490 loss=0.00165
[0.677s] step=491 loss=0.00109
[0.669s] step=492 loss=0.00129
[0.658s] step=493 loss=0.00103
[0.666s] step=494 loss=0.00132
[0.685s] step=495 loss=0.00139
[0.677s] step=496 loss=0.00135
[0.668s] step=497 loss=0.00132
[0.673s] step=498 loss=0.00133
[0.685s] step=499 loss=0.00111
saved model to ./logs/reward_model_2/step-499.pth
[0.683s] step=500 loss=0.00148
[0.698s] step=501 loss=0.00131
[0.716s] step=502 loss=0.00131
[0.689s] step=503 loss=0.00137
[0.679s] step=504 loss=0.00141
[0.673s] step=505 loss=0.00116
[0.671s] step=506 loss=0.00149
[0.669s] step=507 loss=0.00125
[0.675s] step=508 loss=0.00121
[0.699s] step=509 loss=0.00136
[0.672s] step=510 loss=0.00130
[0.687s] step=511 loss=0.00125
[0.675s] step=512 loss=0.00123
[0.665s] step=513 loss=0.00125
[0.677s] step=514 loss=0.00133
[0.669s] step=515 loss=0.00124
[0.665s] step=516 loss=0.00116
[0.678s] step=517 loss=0.00125
[0.672s] step=518 loss=0.00110
[0.671s] step=519 loss=0.00115
[0.680s] step=520 loss=0.00122
[0.686s] step=521 loss=0.00147
[0.673s] step=522 loss=0.00134
[0.668s] step=523 loss=0.00120
[0.662s] step=524 loss=0.00120
[0.678s] step=525 loss=0.00117
[0.677s] step=526 loss=0.00145
[0.672s] step=527 loss=0.00119
[0.664s] step=528 loss=0.00158
[0.680s] step=529 loss=0.00140
[0.869s] step=530 loss=0.00137
[0.681s] step=531 loss=0.00116
[0.667s] step=532 loss=0.00134
[0.671s] step=533 loss=0.00144
[0.667s] step=534 loss=0.00138
[0.671s] step=535 loss=0.00128
[0.672s] step=536 loss=0.00132
[0.675s] step=537 loss=0.00117
[0.674s] step=538 loss=0.00119
[0.682s] step=539 loss=0.00134
[0.679s] step=540 loss=0.00130
[0.666s] step=541 loss=0.00135
[0.666s] step=542 loss=0.00110
[0.679s] step=543 loss=0.00130
[0.677s] step=544 loss=0.00120
[0.666s] step=545 loss=0.00101
[0.684s] step=546 loss=0.00141
[0.672s] step=547 loss=0.00123
[0.685s] step=548 loss=0.00114
[0.678s] step=549 loss=0.00099
[0.682s] step=550 loss=0.00123
[0.668s] step=551 loss=0.00098
[0.670s] step=552 loss=0.00125
[0.667s] step=553 loss=0.00115
[0.677s] step=554 loss=0.00121
[0.665s] step=555 loss=0.00124
[0.675s] step=556 loss=0.00102
[0.673s] step=557 loss=0.00112
[0.667s] step=558 loss=0.00122
[0.682s] step=559 loss=0.00133
[0.674s] step=560 loss=0.00125
[0.675s] step=561 loss=0.00119
[0.691s] step=562 loss=0.00104
[0.683s] step=563 loss=0.00099
[0.683s] step=564 loss=0.00130
[0.678s] step=565 loss=0.00124
[0.678s] step=566 loss=0.00150
[0.672s] step=567 loss=0.00118
[0.688s] step=568 loss=0.00116
[0.673s] step=569 loss=0.00109
[0.682s] step=570 loss=0.00110
[0.676s] step=571 loss=0.00151
[0.689s] step=572 loss=0.00140
[0.669s] step=573 loss=0.00124
[0.663s] step=574 loss=0.00098
[0.673s] step=575 loss=0.00125
[0.679s] step=576 loss=0.00138
[0.681s] step=577 loss=0.00118
[0.667s] step=578 loss=0.00117
[0.682s] step=579 loss=0.00121
[0.679s] step=580 loss=0.00111
[0.681s] step=581 loss=0.00110
[0.680s] step=582 loss=0.00120
[0.684s] step=583 loss=0.00095
[0.678s] step=584 loss=0.00113
[0.681s] step=585 loss=0.00117
[0.666s] step=586 loss=0.00107
[0.673s] step=587 loss=0.00101
[0.669s] step=588 loss=0.00114
[0.671s] step=589 loss=0.00130
[0.684s] step=590 loss=0.00120
[0.677s] step=591 loss=0.00117
[0.689s] step=592 loss=0.00148
[0.678s] step=593 loss=0.00126
[0.664s] step=594 loss=0.00133
[0.672s] step=595 loss=0.00137
[0.668s] step=596 loss=0.00094
[0.672s] step=597 loss=0.00118
[0.670s] step=598 loss=0.00128
[0.664s] step=599 loss=0.00122
saved model to ./logs/reward_model_2/step-599.pth
[0.709s] step=600 loss=0.00116
